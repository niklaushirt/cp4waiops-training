[{"id":0,"href":"/introduction/","title":"Introduction","parent":"Train the Models","content":" Introduction "},{"id":1,"href":"/introduction/intro_00/","title":"Introduction","parent":"Introduction","content":" Introduction In this Training you will learn how to install IBM CloudPak for AIOps and how to configure some basic functionnalities.\nThe idea is to provide an optimised way for you to learn CP4WAIOPS.\nIn the end you will have a demo environment containing the following components:\nAI Manager OpenLDAP registered with AI Manager AWX (Open Source Ansible Tower) with Playbooks and CP4WAIOPS Runbooks AI Models for Log Anomaly Detectiom Metric Anomaly Detection Event Grouping Similar Incidents Change Risk Topology RobotShop Demo Installation K8s Observer RobotShop Application "},{"id":2,"href":"/introduction/intro_01/","title":"Basic Architecture","parent":"Introduction","content":" Basic Architecture The environement (Kubernetes, Applications, \u0026hellip;) create logs that are being fed into a Log Management Tool (ELK in this case).\nExternal Systems generate Alerts and send them into the AI Manager for Event Grouping. At the same time AI Manager ingests the raw logs coming from the Log Management Tool (ELK) and looks for anomalies in the stream based on the trained model. It also ingests Metric Data and looks for anomalies If it finds an anomaly (logs and/or metrics) it forwards it to the Event Grouping as well. Out of this, AI Manager creates a Story that is being enriched with Topology (Localization and Blast Radius) and with Similar Incidents that might help correct the problem. The Story is then sent to Slack. A Runbook is available to correct the problem but not launched automatically. "},{"id":3,"href":"/introduction/intro_02/","title":"Training Architecture","parent":"Introduction","content":" Optimized Training Architecture For the this specific Demo environment:\nELK is installed for you to kearn how to integrate it For Log Anomaly simulation we\u0026rsquo;ll beusing pre-canned logs for the anomaly detection (inception) For Metrics, we\u0026rsquo;ll be using pre-canned metric data for training and for the anomaly detection (inception) The Events will be created from pre-canned content that is injected into AI Manager There are also pre-canned ServiceNow Incidents as we don‚Äôt do the live integration with SNOW for this training The Webpages that are reachable from the Events are static and hosted on my GitHub The same goes for ServiceNow Incident pages if you don‚Äôt integrate with live SNOW "},{"id":4,"href":"/","title":"Train the Models","parent":"","content":" Welcome to the IBM CloudPak for AIOps Training In this Training you will learn how to install IBM CloudPak for AIOps and how to configure some basic functionnalities.\nThe idea is to provide an optimised way for you to learn CP4WAIOPS.\nIn the end you will have a demo environment containing the following components:\nüöÄ Let\u0026rsquo;s Start\n"},{"id":5,"href":"/prerequisites/","title":"Prerequisites","parent":"Train the Models","content":" Prerequisites "},{"id":6,"href":"/prerequisites/prereq_00/","title":"Get your Cluster","parent":"Prerequisites","content":" Get your ROKS Cluster (IBMers and IBM Partners only) IBMers can get a temporary one from Techzone (ususally valid for up to 8 days)\nCreate a cluster for Practice/Self Education if you don\u0026rsquo;t have an Opportunity Number\nSelect the maximum end date that fits your needs (you can extend the duration once after creation)\nFill-in the remaining fields\nGeograpy: prefer Dallas or London (others might be slower) Worker node count: 5 Flavour: b3c.16x64 ‚ùó OpenShift Version: 4.10 Click Submit\nOnce the cluster is provisioned, don\u0026rsquo;t forget to extend it to 8 days if needed.\n"},{"id":7,"href":"/prerequisites/prereq_01/","title":"Important remarks","parent":"Prerequisites","content":" ‚ö†Ô∏è‚ö†Ô∏è Important remarks before you start ‚ö†Ô∏è‚ö†Ô∏è Those are remarks regarding feedback and problem reports I got from the field.\nThose scripts have been tested thoroughly on different environments and have proven to be VERY reliable.\nIf you think that you hit a problem:\nMake sure that you have provisioned a cluster with 5 worker nodes with 16 CPU and 64 GB each (b3c.16x64 - it\u0026rsquo;s easy to select the wrong size). If you have Pods in 0/0 state verify the Events. If you get Not enough CPU then delete the cluster and provision the correct size. When deploying ROKS I usually use Dallas or London, they are the fastest. On other regions we have seen much worse performance - deployment can take 4-5 times longer. If you see Pods in CrashLoop or other error states, try to wait it out (this can be due to dependencies on other componenets that are not ready yet). Chances are that the deployment will eventually go through. If after 8h you are still stuck, ping me. ‚ùó So simply put: be patient and make sure you have the correct size of cluster provisioned! "},{"id":8,"href":"/installing-operator/","title":"Installing the Operator","parent":"Train the Models","content":" Introduction "},{"id":9,"href":"/installing-operator/install_aimanager_00/","title":"Preparing to run commands","parent":"Installing the Operator","content":" Preparing to run commands The official documentation can be found here.\nBefor continuing, you have to connect to your OpenShift Cluster.\nOpen your Openshift Web Console\nSelect Copy Login Command\nCopy the oc login .. string\nOpen your terminal\nPaste the oc login .. command from above\nClone the GitHub Repository into your directory of choice\ngit clone https://github.com/niklaushirt/cp4waiops-deployer.git Go to the deployer directory\ncd cp4waiops-deployer Now you\u0026rsquo;re good to start with the installation.\n"},{"id":10,"href":"/installing-operator/install_aimanager_01/","title":"Preparing Installation","parent":"Installing the Operator","content":" Preparing Installation Create the namespace (project) Create a namespace called cp4waiops, by running the following command:\noc create namespace cp4waiops Create the OperatorGroup Create the Operator group by running the following command:\ncat \u0026lt;\u0026lt; EOF | oc apply -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: cp4waiops-operator-group namespace: cp4waiops spec: targetNamespaces: - cp4waiops EOF Create the entitlement key pull secret Log in to MyIBM Container Software Library with the IBMid.\nIn the Entitlement keys section, select Copy key to copy your entitlement key to the clipboard.\nRun the following command:\noc create secret docker-registry ibm-entitlement-key \\ --docker-username=cp\\ --docker-password=\u0026lt;entitlement-key\u0026gt; \\ --docker-server=cp.icr.io \\ --namespace=cp4waiops Where \u0026lt;entitlement-key\u0026gt; is the entitlement key that you copied in the previous step.\n"},{"id":11,"href":"/installing-operator/install_aimanager_02/","title":"Install Catalog","parent":"Installing the Operator","content":" Installing the Catalog Run the following command to create the CatalogSource.\ncat \u0026lt;\u0026lt; EOF | oc apply -f - apiVersion: operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: ibm-operator-catalog namespace: openshift-marketplace spec: displayName: ibm-operator-catalog publisher: IBM Content sourceType: grpc image: icr.io/cpopen/ibm-operator-catalog:latest EOF Update the CatalogSource to always use the current image digest by running the following commands:\nIMGDIGEST=`oc get pods -n openshift-marketplace -l=olm.catalogSource=ibm-operator-catalog --no-headers -o=jsonpath=\u0026#34;{.items[0].status.containerStatuses[0].imageID}\u0026#34; -n openshift-marketplace` \u0026amp;\u0026amp; \\ oc patch catalogsource ibm-operator-catalog -n openshift-marketplace --type=json -p \u0026#34;[{ \u0026#34;op\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/image\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\\\u0026#34;icr.io/cpopen/ibm-operator-catalog:latest\\\u0026#34;\u0026#34; }, { \u0026#34;op\u0026#34;: \u0026#34;replace\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/image\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\\\u0026#34;$IMGDIGEST\\\u0026#34;\u0026#34; }]\u0026#34; "},{"id":12,"href":"/installing-operator/install_aimanager_03/","title":"Install Operator","parent":"Installing the Operator","content":" Installing the Operator Run the following command:\ncat \u0026lt;\u0026lt; EOF | oc apply -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: ibm-aiops-orchestrator namespace: cp4waiops spec: channel: v3.5 installPlanApproval: Automatic name: ibm-aiops-orchestrator source: ibm-operator-catalog sourceNamespace: openshift-marketplace EOF ``\n"},{"id":13,"href":"/installing-operator/install_aimanager_04/","title":"Check Installation","parent":"Installing the Operator","content":" Check Operator is ready Verify that the Operator is running.\nEither run the following: oc get csv -n cp4waiops And you should see TODO entries with Succeeded state\nNAME DISPLAY VERSION REPLACES PHASE aimanager-operator.v3.5.1 IBM Watson AIOps AI Manager 3.5.1 Succeeded aiopsedge-operator.v3.5.1 IBM Watson AIOps Edge 3.5.1 Succeeded asm-operator.v3.5.1 IBM Netcool Agile Service Manager 3.5.1 Succeeded elasticsearch-operator.5.5.3 OpenShift Elasticsearch Operator 5.5.3 Succeeded ibm-aiops-ir-ai.v3.5.1 IBM Watson AIOps Issue Resolution AI \u0026amp; Analytics 3.5.1 Succeeded ibm-aiops-ir-core.v3.5.1 IBM Watson AIOps Issue Resolution Core 3.5.1 Succeeded ibm-aiops-ir-lifecycle.v3.5.1 IBM Cloud Pak for Watson AIOps Lifecycle 3.5.1 Succeeded ibm-aiops-orchestrator.v3.5.1 IBM Cloud Pak for Watson AIOps AI Manager 3.5.1 Succeeded ibm-automation-core.v1.3.11 IBM Automation Foundation Core 1.3.11 ibm-automation-core.v1.3.10 Succeeded ibm-automation-elastic.v1.3.10 IBM Elastic 1.3.10 ibm-automation-elastic.v1.3.9 Succeeded ibm-automation-eventprocessing.v1.3.11 IBM Automation Foundation Event Processing 1.3.11 ibm-automation-eventprocessing.v1.3.10 Succeeded ibm-automation-flink.v1.3.10 IBM Automation Foundation Flink 1.3.10 ibm-automation-flink.v1.3.9 Succeeded ibm-automation.v1.3.11 IBM Automation Foundation 1.3.11 ibm-automation.v1.3.10 Succeeded ibm-cloud-databases-redis.v1.4.3 IBM Operator for Redis 1.4.3 ibm-cloud-databases-redis.v1.4.2 Succeeded ibm-common-service-operator.v3.21.0 IBM Cloud Pak foundational services 3.21.0 Succeeded ibm-management-kong.v3.5.1 IBM Internal - IBM Watson AIOps Kong 3.5.1 Succeeded ibm-postgreservice-operator.v3.5.1 IBM Postgreservice 3.5.1 Succeeded ibm-secure-tunnel-operator.v3.5.1 IBM Secure Tunnel 3.5.1 Succeeded ibm-vault-operator.v3.5.1 IBM Vault Operator 3.5.1 Succeeded ibm-watson-aiops-ui-operator.v3.5.1 IBM Watson AIOps UI 3.5.1 Succeeded Or check your OpenShift Web Console\n"},{"id":14,"href":"/installing-ai-manager/","title":"Installing AI Manager","parent":"Train the Models","content":" Introduction "},{"id":15,"href":"/installing-ai-manager/install_aimanager_00/","title":"Install AI Manager","parent":"Installing AI Manager","content":" Creating the AI Manager Instance Run the following command to create an instance of AI Manager.\ncat \u0026lt;\u0026lt; EOF | oc apply -f - apiVersion: orchestrator.aiops.ibm.com/v1alpha1 kind: Installation metadata: name: ibm-cp-watson-aiops namespace: cp4waiops spec: imagePullSecret: ibm-entitlement-key license: accept: true pakModules: - name: aiopsFoundation enabled: true - name: applicationManager enabled: true - name: aiManager enabled: true - name: connection enabled: false size: small storageClass: ibmc-file-gold-gid storageClassLargeBlock: ibmc-block-gold EOF This takes some time depending on what region of ROKS you have chosen. Wait up to 45 minutes for the installation to complete.\nThis works only on IBM ROKS. If you want to install on another platform you will have to adapt storageClass and storageClassLargeBlock to your available storage classes.\n"},{"id":16,"href":"/installing-ai-manager/install_aimanager_01/","title":"Check Installation","parent":"Installing AI Manager","content":" Check AI Manager is ready ‚ùó This takes some time depending on what region of ROKS you have chosen. Wait up to 45 minutes for the installation to complete.\nCheck with the Command Line Run the following:\noc get po -n cp4waiops | grep -v Completed | grep -v Error |grep \u0026#34;0/\u0026#34; oc get po -n cp4waiops | grep -v Completed | grep -v Error |grep -v \u0026#34;0/\u0026#34; |wc -l| tr -d \u0026#39; \u0026#39; oc get po -n cp4waiops | grep -v Completed | grep -v Error |grep \u0026#34;0/\u0026#34; |wc -l| tr -d \u0026#39; \u0026#39; This will list the Pods that are not Ready yet.\nüöÄ And when done you should get only the numbers 129 and 0.\nCheck with your OpenShift Web Console Select Pods and your cp4waiops Project\nFilter for the relevant statuses\nThe drop-down also shows you the number of Pods for the different statuses.\nSort by Ready column\nThis allows you to follow along the progress of the installation.\nüöÄ When done you should have 129 Pods in Running status and all Pods should be 1/1, 2/2, 3/3, ...\n"},{"id":17,"href":"/installing-training-resources/","title":"Installing Training resources","parent":"Train the Models","content":" Introduction "},{"id":18,"href":"/installing-training-resources/install_aimanager_00/","title":"Introduction","parent":"Installing Training resources","content":" Installing Training resources This will install resources that you will need for the configuration of AI Manager in the next chapter.\nThose are assets that typically already exist at a customer.\nOpenLDAP AWX (Open Source Ansible Tower) with preloaded Playbooks RobotShop Demo App Demo Service Account This will also load training data for:\nLog Anomalies\nYou will integrate with your live ELK instance but you probably don\u0026rsquo;t have 2-3 days to wait for ELK to collect enough logs. So we\u0026rsquo;ll train on this pre-canned Log Data.\nMetric Anomalies\nFor this training we won\u0026rsquo;t have a Metric provider (Instana, \u0026hellip;) so we\u0026rsquo;ll train on pre-canned Metric Data. If you want you can always integrate an existing Metric Source on top of the provided training data.\nService Now - Similar Incidents\nFor this training we won\u0026rsquo;t have a Service Now Instance so we\u0026rsquo;ll train on pre-canned SNOW Data. If you want you can always integrate an existing SNOW instance on top of the provided training data. You can find documentation here\n"},{"id":19,"href":"/installing-training-resources/install_aimanager_01/","title":"Installing Training Resources","parent":"Installing Training resources","content":" Installing Training resources Run the following code to start the creation of the Training Resources.\ncat \u0026lt;\u0026lt; EOF | oc apply -f - kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: installer-default-default roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: default namespace: default --- apiVersion: batch/v1 kind: Job metadata: name: waiops-easy-install-aimanager-practicum namespace: default spec: serviceAccountName: installer-default-default template: spec: containers: - name: install image: niklaushirt/cp4waiops-tools:1.3 imagePullPolicy: IfNotPresent resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;150m\u0026#34; limits: memory: \u0026#34;1256Mi\u0026#34; cpu: \u0026#34;1200m\u0026#34; command: - /bin/sh - -c - | #!/bin/bash #set -x echo \u0026#34;*****************************************************************************************************************************\u0026#34; echo \u0026#34; ‚úÖ STARTING: INSTALL AI Manager with Demo Content\u0026#34; echo \u0026#34;*****************************************************************************************************************************\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;------------------------------------------------------------------------------------------------------------------------------\u0026#34; echo \u0026#34; üì• Clone Repo https://github.com/niklaushirt/cp4waiops-deployer.git\u0026#34; git clone https://github.com/niklaushirt/cp4waiops-deployer.git cd cp4waiops-deployer echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;------------------------------------------------------------------------------------------------------------------------------\u0026#34; echo \u0026#34; üöÄ Prepare Ansible\u0026#34; ansible-galaxy collection install community.kubernetes:1.2.1 ansible-galaxy collection install kubernetes.core:2.2.3 ansible-galaxy collection install cloud.common pip install openshift pyyaml kubernetes echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;------------------------------------------------------------------------------------------------------------------------------\u0026#34; echo \u0026#34; üöÄ Starting Installation\u0026#34; ansible-playbook ./ansible/00_cp4waiops-install.yaml -e \u0026#34;config_file_path=./configs/cp4waiops-roks-aimanager-practicum.yaml\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;*****************************************************************************************************************************\u0026#34; echo \u0026#34; ‚úÖ DONE\u0026#34; echo \u0026#34;*****************************************************************************************************************************\u0026#34; while true do sleep 1000 done restartPolicy: Never backoffLimit: 4 EOF You should get:\nclusterrolebinding.rbac.authorization.k8s.io/installer-default-default created or unchanged if you have already lauched it once job.batch/waiops-easy-install-aimanager-practicum created "},{"id":20,"href":"/installing-training-resources/install_aimanager_02/","title":"Check Installation","parent":"Installing Training resources","content":" Check Training Resources are ready ‚ùó This takes some time depending on what region of ROKS you have chosen. Wait up to 45 minutes for the installation to complete.\nYou can follow along the process by running:\n./tools/11_fzth/stream_remote_logs.sh Or through the OpensHift Web Console:\nSelect default Namespace\nSelect Pods\nClick on the waiops-easy-install-aimanager-practicum-... Pod\nSelect Logs\nüöÄ And when done you should get the following with failed=0.\nPLAY RECAP ********************************************************************* localhost : ok=XXX changed=XXX unreachable=0 failed=0 skipped=XXX rescued=0 ignored=0 ***************************************************************************************************************************** ‚úÖ DONE ***************************************************************************************************************************** "},{"id":21,"href":"/configure-ai-manager/","title":"Configure AI Manager","parent":"Train the Models","content":" Configure AI Manager "},{"id":22,"href":"/configure-ai-manager/configure_aimanager_00/","title":"Get the information","parent":"Configure AI Manager","content":" Get the configuration information Run the following command to create an instance of AI Manager. ./tools/11_fzth/get_configuration_info.sh This will provide you with all the information and details that you need to configure AI Manager in this chapter.\n‚ö†Ô∏è You can also save the information to a file to keep it handy\n./tools/11_fzth/get_configuration_info.sh \u0026gt; MY_CONFIGURATION.txt "},{"id":23,"href":"/configure-ai-manager/configure_aimanager_01/","title":"First Login","parent":"Configure AI Manager","content":" Login to AI Manager In your OpenShift Console click on the Applications Menu\nSelect CP4WAIOps Demo UI\nLogin with token P4ssw0rd!\nCopy the Admin Password\nOpen AI Manager\nSelect IBM provided credentials\nLogin with admin user and the password you copied in the step above\nWelcome to AI Manager\n"},{"id":24,"href":"/configure-ai-manager/configure_aimanager_02/","title":"Initialize ELK","parent":"Configure AI Manager","content":" Initialize ELK In your OpenShift Console click on the Applications Menu\nSelect Logging\nAccept default values\nInput app* for the index pattern\nClick Next Step\nSelect @timestamp for time filter\nClick Create Index Pattern\nELK is now configured. Verify that you have Logs coming in.\n"},{"id":25,"href":"/configure-ai-manager/configure_aimanager_03/","title":"Configure LDAP","parent":"Configure AI Manager","content":" Configure LDAP integration Create LDAP provider In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Access Control\nIn the top right Click Identity provider configuration\nYou might have to re-login with your admin user\nIn the top right Click New Connection\nSelect LDAP from the dropdown\nClick Next\nüîé Get the data from your configuration info - section 2.1 Configure LDAP\n./tools/11_fzth/get_configuration_info.sh Fill out the first section of fields:\nConnection name: LDAP Server type: Custom Base DN: dc=ibm,dc=com Bind DN: cn=admin,dc=ibm,dc=com Bind DN password: P4ssw0rd! LDAP server URL: ldap://openldap.openldap:389 Click Test connection. You should get Successful connection\nFill out the rest of the fields:\nGroup filter: (\u0026amp;(cn=%v)(objectclass=groupOfUniqueNames)) User filter: (\u0026amp;(uid=%v)(objectclass=Person)) \u0026lt;-- Thats the only value you should have to change Group ID map: *:cn User ID map: *:uid Group member ID map: groupOfUniqueNames:uniqueMember Click Create\nYou should get a LDAP entry in the provider list\nCreate User Go back to AI Manager, click on the \u0026ldquo;Hamburger\u0026rdquo; Menu and select Access Control\nIn the top right Click Add users\nIn the search box type demo\nClick on the demo/demo/demo@ibm.com line\nClick Next\nClick Assign roles directly\nCheck Administrator role\nClick Next\nClick Add\nLogin as Demo In AI Manager, click on the round image in the top right and select Log Out\nClick Logout\nClick Log in\nEnter credentials demo and P4ssw0rd! (this information is stored in the LDAP server)\nWelcome back in AI Manager as user Demo\n"},{"id":26,"href":"/configure-ai-manager/configure_aimanager_04/","title":"Configure ELK","parent":"Configure AI Manager","content":" Configure ELK In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Define/Data and tool integrations\nClick Add connection\nUnder ELK, click on Add connection\nClick Connect\nName it ELK\nüîé Get the data from your configuration info - section 2.2 Configure asdfdsafdsa\n./tools/11_fzth/get_configuration_info.sh Fill out the fields on the first page:\nELK service URL: from script Authentication type: Token Token: from script Kibana URL: from script Kibana port: 443 Mapping: { \u0026#34;codec\u0026#34;: \u0026#34;elk\u0026#34;, \u0026#34;message_field\u0026#34;: \u0026#34;message\u0026#34;, \u0026#34;log_entity_types\u0026#34;: \u0026#34;kubernete\ts.container_image_id, kubernetes.host, kubernetes.pod_name, kubernetes.namespace_name\u0026#34;, \u0026#34;instance_id_field\u0026#34;: \u0026#34;kubernetes.container_name\u0026#34;, \u0026#34;rolling_time\u0026#34;: 10, \u0026#34;timestamp_field\u0026#34;: \u0026#34;@timestamp\u0026#34; } ``\nClick Test connection. You should get Connection successful!\nClick Next\nFill out the Field mapping:\nMapping: { \u0026#34;codec\u0026#34;: \u0026#34;elk\u0026#34;, \u0026#34;message_field\u0026#34;: \u0026#34;message\u0026#34;, \u0026#34;log_entity_types\u0026#34;: \u0026#34;kubernetes.container_image_id, kubernetes.host, kubernetes.pod_name, kubernetes.namespace_name\u0026#34;, \u0026#34;instance_id_field\u0026#34;: \u0026#34;kubernetes.container_name\u0026#34;, \u0026#34;rolling_time\u0026#34;: 10, \u0026#34;timestamp_field\u0026#34;: \u0026#34;@timestamp\u0026#34; } Click Next\nTurn On Data collection\nSelect Live data for continuous AI training and anomaly detection\nClick Done\nMake sure that the Data Collection and Connection Status turn green after a few minutes\n"},{"id":27,"href":"/configure-ai-manager/configure_aimanager_05/","title":"Configure Runbooks","parent":"Configure AI Manager","content":" Configure Runbooks Create Ansible Tower Connection In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Define/Data and tool integrations\nClick Add connection\nUnder Ansible Automation Controller, click on Add connection\nClick Connect\nüîé Get the data from your configuration info - section 2.3 Configure Runbooks - Ansible Automation Controller\n./tools/11_fzth/get_configuration_info.sh Fill out the fields:\nURL for REST API: from script Authentication type: User ID/Password User: admin Password: from script ``\nClick Done\nMake sure that the Connection Status turn green after a few seconds\nCheck integration In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/Automations\nSelect tab Actions\nVerify that the Ansible Playbooks have been imported\nCreate Runbooks Select tab Runbooks\nClick Create Runbook\nName it RobotShop Mitigate MySQL Problem\nClick Add automated step\nSelect CP4WAIOPS Mitigate Robotshop Ratings Outage\nClick Select this action\nClick Mapping / Select\nSelect New runbook parameter\nSelect tab\nüîé Get the data from your configuration info - section 2.4 Configure Runbooks - Runbook Parameters\n./tools/11_fzth/get_configuration_info.sh Replace PROVIDE: my_k8s_apiurl and my_k8s_apikey in field Default value (optional) with the value from the script\nClick Save\nClick Save again\nClick Actions and Publish\n"},{"id":28,"href":"/configure-ai-manager/configure_aimanager_06/","title":"Configure Policies","parent":"Configure AI Manager","content":" Configure Policies Enable Story creation Policy In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/Automations\nSelect tab Policies\nClick on the Tag dropdown\nSelect Stories and Runbooks\nTurn on Policy Default story creation policy for all alerts\nCreate Runbook Assignment Policy Click on Create Policy\nClick on Assign a runbook to alerts\nName it RobotShop Mitigate MySQL Problem\nScroll down to Condition sets\nClick in field Property\nType name\nSelect resource / name\nClick in field Value\nType mysql\nSelect String: mysql\nCheck runbook RobotShop Mitigate MySQL Problem\nCheck Use default parameter value\nYour list of Policies should now look like this\n"},{"id":29,"href":"/configure-ai-manager/configure_aimanager_07/","title":"Configure Applications","parent":"Configure AI Manager","content":" Create Kubernetes Observer In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Define/Data and tool integrations\nClick Add connection\nUnder Kubernetes, click on Add connection\nClick Connect\nüîé Get the data from your configuration info - section 2.5 Configure Applications - RobotShop Kubernetes Observer\n./tools/11_fzth/get_configuration_info.sh Fill out the first section of fields (Add connection):\nName: RobotShop Data center: robot-shop Click Next\nFill out the first section of fields (Set advanced options):\nKubernetes master IP address: 172.21.0.1 Kubernetes API port: 443 Token:\tfrom script Trust all HTTPS certificates: true Correlate analytics events:\ttrue Namespaces to observe: robot-shop Click Next\nClick Done\nThe Integration should show Running and eventually Successunder Schedule\nConfigure Applications In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/Resource management\nSelect tab Applications\nClick Define Application\nSelect the two Resource Group\nClick Next\nClick Next\nEnter Name RobotShop\nClick on the heart to Mark as favorite\nEnter 1000 into Estimated cost per minute for service disruption\nClick Define Applications\n"},{"id":30,"href":"/train-the-models/","title":"Train the Models","parent":"Train the Models","content":" Configure AI Manager "},{"id":31,"href":"/train-the-models/configure_aimanager_00/","title":"Log Anomalies","parent":"Train the Models","content":" Define Log Anomalies Training In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/AI Model Management\nUnder Log anomaly detection - natural language, click on Set up training\nClick Next\nUnder Select data check Custom\nSelect Start date as March, 3rd 2022\nSelect End date as March, 4rd 2022\nClick Next\nClick Next\nClick Next\nUnder Deployment type check On completion\nClick Done\nRun Log Anomalies Training Click on the three dots in the upper right corner of the Log anomaly detection - natural language card\nSelect Start Training\nStatus should say In progress\nAnd eventually say Deployed\n"},{"id":32,"href":"/train-the-models/configure_aimanager_01/","title":"Metric Anomalies","parent":"Train the Models","content":" Define Metric Anomalies Training In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/AI Model Management Under Metric anomaly detection, click on Set up training Click Next Click Next Click Done Run Metric Anomalies Training Click on the three dots in the upper right corner of the Metric anomaly detection card Select Start Training Status should say In progress And eventually say Deployed "},{"id":33,"href":"/train-the-models/configure_aimanager_02/","title":"Similar Incidents","parent":"Train the Models","content":" Define Similar Incidents Training In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/AI Model Management Under Similar Incidents, click on Set up training Click Next Click Next Click Done Run Similar Incidents Training Click on the three dots in the upper right corner of the Similar Incidents card Select Start Training Status should say In progress And eventually say Deployed "},{"id":34,"href":"/train-the-models/configure_aimanager_03/","title":"Change Risk","parent":"Train the Models","content":" Define Change Risk Training In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/AI Model Management Under Change Risk, click on Set up training Click Next Click Next Under Deployment type check On completion Click Done Run Change Risk Training Click on the three dots in the upper right corner of the Change Risk card Select Start Training Status should say In progress And eventually say Deployed "},{"id":35,"href":"/train-the-models/configure_aimanager_04/","title":"Temporal Grouping","parent":"Train the Models","content":" Define Temporal Grouping Training In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/AI Model Management Under Temporal Grouping, click on Set up training Click Next Click Next Click Done Run Temporal Grouping Training Click on the three dots in the upper right corner of the Temporal Grouping card Select Start Training Status should say In progress And eventually say Deployed "},{"id":36,"href":"/train-the-models/configure_aimanager_05/","title":"Check Training","parent":"Train the Models","content":" Check Training Status Check your Training Cards. All should be green and say Deployed\n"},{"id":37,"href":"/test-and-demo/","title":"Test And Demo","parent":"Train the Models","content":" Configure AI Manager "},{"id":38,"href":"/test-and-demo/configure_aimanager_00/","title":"Create Test Incident","parent":"Test And Demo","content":" Create Test Incident In your OpenShift Console click on the Applications Menu\nSelect CP4WAIOps Demo UI\nLogin with token P4ssw0rd!\nClick on Create Incident Memory Leak\nWait for pop-up to go away and the Demo UI going back to the homepage\n"},{"id":39,"href":"/test-and-demo/configure_aimanager_01/","title":"Examine the Incident","parent":"Test And Demo","content":" Examine the Incident In the AI Manager \u0026ldquo;Hamburger\u0026rdquo; Menu select Operate/Stories and Alerts\nClick on Alerts\nYou should see some Alerts coming in\nClick on Stories\nYou should see some Stories\nClick on the first Story in the list (it should be P2 or P1 but the name can differ)\nYou should see some Stories\nYou should see the detail of the Story, with the Probable Cause, the Runbooks and the Similar Incidents\nClick on Alerts, you should see the list of grouped Alerts that are part of the Story\nClick on Topology, you should see the Topology of the components being impacted by the incident\nClick on Overview to go back to the Story overview\nYou can now start to play around with the Story:\nAssign to a user Change Status Change Severity Run the Runbook See the Similar Incidents The links to the similar incidents are pre-canned, static Webpages, as we don\u0026rsquo;t have a live ServiceNow instance\n"},{"id":40,"href":"/test-and-demo/configure_aimanager_02/","title":"Clear the Incident","parent":"Test And Demo","content":" Clear the Incident Go back to the Demo UI\nClick on Clear Stories and Events\nWait for pop-up to go away and the Demo UI going back to the homepage\nThe Alerts will be Closed and the Stories Resolved\nYou will have to wait for about 10 minutes for them to disappear (you can recreate the incident earlier, which will just re-open the existing Stories )\n"},{"id":41,"href":"/posts/","title":"Blog","parent":"Train the Models","content":" CP4WatsonAIOps CP4WAIOPS "},{"id":42,"href":"/posts/my-first-post/","title":"Welcome","parent":"Blog","content":" Welcome to the IBM CloudPak for AIOps Training In this Training you will learn how to install IBM CloudPak for AIOps and how to configure some basic functionnalities.\nThe idea is to provide an optimised way for you to learn CP4WAIOPS.\nIn the end you will have a demo environment containing the following components:\n"},{"id":43,"href":"/categories/","title":"Categories","parent":"Train the Models","content":""},{"id":44,"href":"/tags/","title":"Tags","parent":"Train the Models","content":""}]